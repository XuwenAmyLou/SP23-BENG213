{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366af5e9",
   "metadata": {},
   "source": [
    "$$Lecture\\quad04/18$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdbe3f",
   "metadata": {},
   "source": [
    "p-value issues:\n",
    "1. assumed distribution\n",
    "2. noisy data, non-parametric methods does not work very well \n",
    "3. underpowered studies (often require more studies to have a good confidence interval)\n",
    "4. black/white thinking in terms of the results being reported (a very clear cut line for p-value, but it's silly to conduct science this way)\n",
    "5. small effect sizes can result in p-values (when sample is small, the correlation may be high. small p-value at large n -> maybe your statistical test is not appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf0c82",
   "metadata": {},
   "source": [
    "Computing confidence intervals:\n",
    "1. Pr(-c<T<c) = %confidence / 100, the probability of your distribution/variable follwoing between these two ranges. \n",
    "2. different distribution have different formulas to compute the confience interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943f54e",
   "metadata": {},
   "source": [
    "P-value hacking\n",
    "defn: inappropriately adjusting the workflows to minimize p-value\n",
    "1. try many methods till you get a desired result\n",
    "2. try multiple hypothesis with no correction\n",
    "3. excluding sample\n",
    "4. monitoring experiment and stop right after getting a significant result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bff4e3",
   "metadata": {},
   "source": [
    "Bayesian analysis:\n",
    "1. dealing with both null and alternative hypotheses\n",
    "2. not strickly better, but has advantages for builiding models\n",
    "\n",
    "Hypothesis testing\n",
    "1. frequetsist, assuming null hypothesis is true, probability of observing the data?\n",
    "2. bayesian, given the data, what is the probability that hypothesis is true?\n",
    "\n",
    "bayesian emthods:\n",
    "1. gaussian mixture model\n",
    "2. empirical bayesian estimation of latent variables\n",
    "3. bayesian hypothesis tesitng\n",
    "4. bayesian classfiers\n",
    "5. bayesian parameterization\n",
    "\n",
    "why bayesian:\n",
    "1. it leanrs from the data\n",
    "2. use prior distribution and allows you to define the hypothesis that you want to test. Simplify the task for your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbdc4a3",
   "metadata": {},
   "source": [
    "SOME TERMS:\n",
    "\n",
    "likelihood ratio\n",
    "1. ratio of probabilities $$\\frac{of\\quad data\\quad under\\quad alternative\\quad hypothesis}{of data\\quad under \\quad null}$$\n",
    "2. bayes factor $$K = \\frac{Pr(D|M_1)}{Pr(D|M_2}$$\n",
    "3. Monte Hall Problem:\n",
    "monte hall probelm, behind one door is a car, behind two doors have goats\n",
    "if the host open one showing a goat, should you switch or not? (statistically, you need to switch)\n",
    "4. Bayes statistical questios: alice and bob game question\n",
    "you can calculate things, but the math gets difficult to solve\n",
    "5. conditional probability:\n",
    "bayesian, you can continue to update your probability based on the series of data/events\n",
    "\n",
    "\n",
    "go through prior, posterior, etc.., all terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf982e3",
   "metadata": {},
   "source": [
    "05/11 lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19c974",
   "metadata": {},
   "source": [
    "1. performance metrics\n",
    "2. model interpretation\n",
    "3. dat partitioning \n",
    "4. workflows and optimizing hyperparameters\n",
    "5. advice for best practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bd753",
   "metadata": {},
   "source": [
    "performance metrics:\n",
    "this is more for classification model, but none of them will give you a complete picture by itself\n",
    "1. accuracy is not good for class imbalance\n",
    "2. true positive rate / sensitivity: true positives / all positives\n",
    "3. true negative rate / specificity\n",
    "4. matthews correlation coefficient: works very well with imbalanced classification\n",
    "\n",
    "don't use F1 or ROC alone, use both of the curves at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29213b24",
   "metadata": {},
   "source": [
    "lins of methods are listed in the lecture slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b32eb6",
   "metadata": {},
   "source": [
    "methods of ordering/dividing testing and training data:\n",
    "1. permutation (moving data around, sampling data from original dataset)\n",
    "2. bootstrappingï¼š resampling with replacement.\n",
    "    parametric bootstrap: use your data's mean, standard deviation, etc... \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2625b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c72253bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a235acfe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c09ab41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d120af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec6a8253",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
